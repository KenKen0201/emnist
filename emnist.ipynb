{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of this model on MNIST test data: \n",
    "1. 0.22% test error rate with ensemble of 10 CNNs\n",
    "2. 0.21% test error rate with ensemble of 6 selected CNNs\n",
    "3. 0.26% test error rate for best single model (model was trained for a few more epochs)\n",
    "\n",
    "## Test error rates of this model on EMNIST test data:\n",
    "Model was trained from scratch on EMNIST Digits training data using realtime data augmentation. All test error rates in percent.\n",
    "1. 0.2499997615814209 test error rate with ensemble of 10 CNNs after 128 epochs\n",
    "2. 0.1999974250793457 test error rate with ensemble of 10 CNNs after 144 epochs\n",
    "3. 0.18749833106994629 test error rate with ensemble of 10 CNNs after 160 epochs\n",
    "4. 0.17499923706054688 test error rate with ensemble of 10 CNNs after 192 epochs\n",
    "5. 0.17750263214111328 test error rate with ensemble of 10 CNNs after 208 epochs\n",
    "6. 0.1699984073638916 test error rate with ensemble of 10 CNNs after 240 epochs\n",
    "6. 0.209999084473 test error rate for best single model after 240 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Lambda, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam as Adam\n",
    "\n",
    "# try leaky relu\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use device=gpu in .theanorc in the next release to make use of the gpuarray backend. For now, this would break the history plotting part of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used to save and load training histories\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import resource, sys\n",
    "\n",
    "# we would reach recursion limit when saving training history otherwise\n",
    "resource.setrlimit(resource.RLIMIT_STACK, (2**29,-1))\n",
    "sys.setrecursionlimit(2**29 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load EMNIST Digits dataset\n",
    "Introduced by https://arxiv.org/abs/1702.05373v1 downloaded from https://www.nist.gov/itl/iad/image-group/emnist-dataset (Matlab format dataset). The matlab format dataset can be conveniently imported with scipy.io.loadmat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emnist = spio.loadmat(\"datasets/matlab/emnist-digits.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training dataset\n",
    "x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
    "x_train = x_train.astype(np.float32)\n",
    "\n",
    "# load training labels\n",
    "y_train = emnist[\"dataset\"][0][0][0][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# load test labels\n",
    "y_test = emnist[\"dataset\"][0][0][1][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store labels for visualization\n",
    "train_labels = y_train\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape using matlab order\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28, order=\"A\")\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28, order=\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 1, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels should be onehot encoded\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify we have imported the data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which sample to look at\n",
    "samplenum = 5437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0948d37f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB8IivADQf0fPOZqxOiZMBIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd095a51b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = x_train[samplenum]\n",
    "\n",
    "# visualize image\n",
    "plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show label for sample image\n",
    "train_labels[samplenum][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = test_labels.reshape(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and standard deviation\n",
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to normalize input data\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batchnorm + dropout + data augmentation\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28), output_shape=(1,28,28)),\n",
    "        Conv2D(32, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "Use keras's data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=12, width_shift_range=0.1, shear_range=0.3,\n",
    "                        height_shift_range=0.1, zoom_range=0.1, data_format='channels_first')\n",
    "batches = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(x_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(test_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0948617f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEIoQGMMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0948d3da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load ONE image from training set to display on screen\n",
    "img = x_train[1]\n",
    "\n",
    "# visualize original image\n",
    "plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trick our generator into believing img has enough dimensions\n",
    "# and get some augmented images for our single test image\n",
    "img = np.expand_dims(img, axis=0)\n",
    "aug_iter = gen.flow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_img = next(aug_iter)[0].astype(np.float32)\n",
    "aug_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAABqCAYAAABZAFxNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0948d3cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show augmented images\n",
    "f = plt.figure(figsize=(12,6))\n",
    "for i in range(8):\n",
    "    sp = f.add_subplot(2, 26//3, i+1)\n",
    "    sp.axis('Off')\n",
    "    aug_img = next(aug_iter)[0].astype(np.float32)\n",
    "    plt.imshow(aug_img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "Here we create ten models and fit them to our augmented data. We use the mean prediction from all ten classifiers as our final prediction. This should average out errors in our classifiers and enable us to predict with higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models using saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(10):\n",
    "    m = create_model()\n",
    "    m.load_weights('weights/240epochs_weights_model_'+str(i)+'.pkl')\n",
    "    models.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or create and train ten models from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "histories = []\n",
    "\n",
    "# create and train ten models from scratch\n",
    "for i in range(10):\n",
    "    m = create_model()\n",
    "    h = m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=32, verbose=0,\n",
    "                        validation_data=test_batches, validation_steps=validation_steps)\n",
    "    # save model weights\n",
    "    m.save_weights(\"weights/Xepochs_weights_model_{}.pkl\".format(str(i)))\n",
    "    # save corresponding training history\n",
    "    f = open(\"history/Xepochs_history_model_{}.pkl\".format(str(i)),\"wb\")\n",
    "    pickle.dump(h, f)\n",
    "    f.close()\n",
    "    \n",
    "    models.append(m)\n",
    "    histories.append(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train existing models for a few more epochs\n",
    "Train models for additional 16 epochs and save model weights as well as corresponding training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    h = m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=16, verbose=0,\n",
    "                        validation_data=test_batches, validation_steps=validation_steps)\n",
    "    # save model weights\n",
    "    m.save_weights(\"weights/256epochs_weights_model_{}.pkl\".format(str(i)))\n",
    "    # save corresponding training history\n",
    "    f = open(\"history/256epochs_history_model_{}.pkl\".format(str(i)),\"wb\")\n",
    "    pickle.dump(h, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Ensemble of 10 CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(x_test, batch_size=eval_batch_size) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1699984073638916"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display error rate in percent\n",
    "(1 - keras.metrics.categorical_accuracy(y_test, avg_preds).eval().mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show test error rate of every model separately\n",
    "All test error rates in percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 epochs: 0.34999847412109375 on ensemble of 10 models\n",
    "1. 0.470000505447\n",
    "2. 0.480002164841\n",
    "3. 0.569999217987\n",
    "4. 0.599998235703\n",
    "5. 0.660002231598\n",
    "6. 0.550001859665\n",
    "7. 0.429999828339\n",
    "8. 0.529998540878\n",
    "9. 0.400000810623\n",
    "10. 0.379997491837\n",
    "\n",
    "48 epochs: 0.3099977970123291 on ensemble of 10 models\n",
    "1. 0.470000505447\n",
    "2. 0.480002164841\n",
    "3. 0.38999915123\n",
    "4. 0.559997558594\n",
    "5. 0.510001182556\n",
    "6. 0.520002841949\n",
    "7. 0.379997491837\n",
    "8. 0.419998168945\n",
    "9. 0.520002841949\n",
    "10. 0.440001487732\n",
    "\n",
    "64 epochs: 0.29000043869018555 on ensemble of 10 models (learning rate 0.0001)\n",
    "1. 0.419998168945\n",
    "2. 0.540000200272\n",
    "3. 0.480002164841\n",
    "4. 0.340002775192\n",
    "5. 0.38999915123\n",
    "6. 0.58000087738\n",
    "7. 0.419998168945\n",
    "8. 0.360000133514\n",
    "9. 0.520002841949\n",
    "10. 0.449997186661\n",
    "\n",
    "80 epochs: 0.26000142097473145 on ensemble of 10 models (learning rate 0.0001)\n",
    "1. 0.48999786377\n",
    "2. 0.319999456406\n",
    "3. 0.419998168945\n",
    "4. 0.520002841949\n",
    "5. 0.349998474121\n",
    "6. 0.400000810623\n",
    "7. 0.340002775192\n",
    "8. 0.529998540878\n",
    "9. 0.429999828339\n",
    "10. 0.550001859665\n",
    "\n",
    "96 epochs: 0.26000142097473145 on ensemble of 10 models (learning rate 0.0001)\n",
    "1. 0.440001487732\n",
    "2. 0.349998474121\n",
    "3. 0.419998168945\n",
    "4. 0.529998540878\n",
    "5. 0.440001487732\n",
    "6. 0.429999828339\n",
    "7. 0.379997491837\n",
    "8. 0.300002098083\n",
    "9. 0.449997186661\n",
    "10. 0.609999895096\n",
    "\n",
    "112 epochs: 0.26000142097473145 on ensemble of 10 models (learning rate 0.0001)\n",
    "1. 0.38999915123\n",
    "2. 0.540000200272\n",
    "3. 0.400000810623\n",
    "4. 0.38999915123\n",
    "5. 0.540000200272\n",
    "6. 0.480002164841\n",
    "7. 0.480002164841\n",
    "8. 0.499999523163\n",
    "9. 0.419998168945\n",
    "10. 0.400000810623\n",
    "\n",
    "128 epochs: 0.2499997615814209 on ensemble of 10 models\n",
    "1. 0.48999786377\n",
    "2. 0.38999915123\n",
    "3. 0.480002164841\n",
    "4. 0.419998168945\n",
    "5. 0.419998168945\n",
    "6. 0.330001115799\n",
    "7. 0.319999456406\n",
    "8. 0.440001487732\n",
    "9. 0.379997491837\n",
    "10. 0.370001792908\n",
    "\n",
    "144 epochs: 0.1999974250793457 on ensemble of 10 models\n",
    "1. 0.2749979496\n",
    "2. 0.282502174377\n",
    "3. 0.2749979496\n",
    "4. 0.309997797012\n",
    "5. 0.292497873306\n",
    "6. 0.2749979496\n",
    "7. 0.244998931885\n",
    "8. 0.255000591278\n",
    "9. 0.295001268387\n",
    "10. 0.267499685287\n",
    "\n",
    "160 epochs: 0.18749833106994629 on ensemble of 10 models\n",
    "1. 0.220000743866\n",
    "2. 0.265002250671\n",
    "3. 0.265002250671\n",
    "4. 0.247502326965\n",
    "5. 0.262498855591\n",
    "6. 0.257498025894\n",
    "7. 0.295001268387\n",
    "8. 0.227499008179\n",
    "9. 0.242501497269\n",
    "10. 0.295001268387\n",
    "\n",
    "176 epochs: 0.18749833106994629 on ensemble of 10 models\n",
    "1. 0.239998102188\n",
    "2. 0.249999761581\n",
    "3. 0.239998102188\n",
    "4. 0.269997119904\n",
    "5. 0.262498855591\n",
    "6. 0.269997119904\n",
    "7. 0.269997119904\n",
    "8. 0.227499008179\n",
    "9. 0.252497196198\n",
    "10. 0.284999608994\n",
    "\n",
    "192 epochs: 0.17499923706054688 on ensemble of 10 models\n",
    "1. 0.244998931885\n",
    "2. 0.249999761581\n",
    "3. 0.269997119904\n",
    "4. 0.239998102188\n",
    "5. 0.257498025894\n",
    "6. 0.247502326965\n",
    "7. 0.227499008179\n",
    "8. 0.225001573563\n",
    "9. 0.230002403259\n",
    "10. 0.232499837875\n",
    "\n",
    "208 epochs: 0.17750263214111328 on ensemble of 10 models\n",
    "1. 0.239998102188\n",
    "2. 0.2749979496\n",
    "3. 0.249999761581\n",
    "4. 0.237500667572\n",
    "5. 0.217497348785\n",
    "6. 0.29000043869\n",
    "7. 0.232499837875\n",
    "8. 0.262498855591\n",
    "9. 0.272500514984\n",
    "10. 0.252497196198\n",
    "\n",
    "224 epochs: 0.18749833106994629 on ensemble of 10 models\n",
    "1. 0.252497196198\n",
    "2. 0.234997272491\n",
    "3. 0.244998931885\n",
    "4. 0.244998931885\n",
    "5. 0.244998931885\n",
    "6. 0.237500667572\n",
    "7. 0.257498025894\n",
    "8. 0.227499008179\n",
    "9. 0.277501344681\n",
    "10. 0.247502326965\n",
    "\n",
    "240 epochs: 0.1699984073638916 on ensemble of 10 models\n",
    "1. 0.234997272491\n",
    "2. 0.222498178482\n",
    "3. 0.232499837875\n",
    "4. 0.249999761581\n",
    "5. 0.249999761581\n",
    "6. 0.292497873306\n",
    "7. 0.234997272491\n",
    "8. 0.257498025894\n",
    "9. 0.244998931885\n",
    "10. 0.209999084473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.234997272491\n",
      "2 0.222498178482\n",
      "3 0.232499837875\n",
      "4 0.249999761581\n",
      "5 0.249999761581\n",
      "6 0.292497873306\n",
      "7 0.234997272491\n",
      "8 0.257498025894\n",
      "9 0.244998931885\n",
      "10 0.209999084473\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(models):\n",
    "    pred = np.array(m.predict(x_test, batch_size=eval_batch_size))\n",
    "    print(i+1, (1 - keras.metrics.categorical_accuracy(y_test, pred).eval().mean()) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and plot saved training histories. Utility functions from https://github.com/fchollet/keras/issues/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which model to plot training history of\n",
    "i = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge training histories\n",
    "def merge_dict(dict_list):\n",
    "    dd = defaultdict(list)    \n",
    "    for d in dict_list:\n",
    "        for key, value in d.items():\n",
    "            if not hasattr(value, '__iter__'):\n",
    "                value = (value,)       \n",
    "            [dd[key].append(v) for v in value]\n",
    "    return dict(dd)\n",
    "\n",
    "# load pickled data\n",
    "def load(name):\n",
    "    filename = open(name,\"rb\")\n",
    "    obj = pickle.load(filename)\n",
    "    filename.close()    \n",
    "    return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "histories = glob.glob(\"history/*model_{}*\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histories = sorted(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/js/anaconda3/lib/python3.6/site-packages/theano/sandbox/cuda/type.py:597: UserWarning: config.experimental.unpickle_gpu_on_cpu is set to True. Unpickling CudaNdarray as numpy.ndarray\n",
      "  warnings.warn(\"config.experimental.unpickle_gpu_on_cpu is set to True. Unpickling CudaNdarray as numpy.ndarray\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'norm_input' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ab58b3de93b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# first history would include zero accuracy and mess up our plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-a616d074a86c>\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'norm_input' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# first history would include zero accuracy and mess up our plot\n",
    "h0 = load(histories[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all saved histories\n",
    "for h in histories[2:]:\n",
    "    h1 = load(h)\n",
    "    h0.history = merge_dict([h0.history,h1.history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = h0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jason Brownlee's script to plot model training history:\n",
    "https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "# set x label range, starting with 32\n",
    "r = np.arange(32,224)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(r, history.history['acc'])\n",
    "plt.plot(r, history.history['val_acc'])\n",
    "plt.title(\"model {} accuracy\".format(i))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.xlim(32,224)\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(r, history.history['loss'])\n",
    "plt.plot(r, history.history['val_loss'])\n",
    "plt.title(\"model {} loss\".format(i))\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.xlim(32,224)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try evaluation only with best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_numbers = [0,1,2,8,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_models = []\n",
    "\n",
    "for i in best_model_numbers:\n",
    "    best_models.append(models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(x_test, batch_size=eval_batch_size) for m in best_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display error rate in percent\n",
    "(1 - keras.metrics.categorical_accuracy(y_test, avg_preds).eval().mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train single model some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single model, train for a few epochs, and check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which model to train\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload weights in case of overfitting\n",
    "# models[i].load_weights(\"weights/weights_emnist_model_0.2475_\"+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models[i].optimizer.lr = 0.0001\n",
    "history = models[i].fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate accuracy of single model\n",
    "pred = np.array(models[i].predict(x_test, batch_size=eval_batch_size))\n",
    "print(i, (1 - keras.metrics.categorical_accuracy(y_test, pred).eval().mean()) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# models[i].save_weights(\"weights/weights_emnist_model_0.2475_\"+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix for python3\n",
    "import pydotplus as pydot\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(models[0], to_file='model.png')\n",
    "\n",
    "# visualize our model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(models[0]).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize predictions for best performing single model\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "\n",
    "todo: show labels with highest/lowest uncertainty (it may be necessary to change the softmax activation to something else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load saved weights\n",
    "m.load_weights(\"weights/weights_mnist+32epochs_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict classes\n",
    "preds = m.predict_classes(x_test, batch_size=eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = np.where(preds==test_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect = np.where(preds!=test_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of images to view\n",
    "n_view = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import permutation\n",
    "\n",
    "# get a random selection of correctly predicted images\n",
    "idx = permutation(correct)[:n_view]\n",
    "idx_incorrect = permutation(incorrect)[:n_view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_correct = preds[idx]\n",
    "preds_incorrect = preds[idx_incorrect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = x_test[idx]\n",
    "imgs_incorrect = x_test[idx_incorrect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few correct labels at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,6))\n",
    "\n",
    "for i in range(n_view):\n",
    "    sp = f.add_subplot(3, 10, i+1)\n",
    "    sp.axis('Off')\n",
    "    sp.set_title(preds_correct[i])\n",
    "    img = imgs[i].astype('float32')\n",
    "    plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ground truth labels\n",
    "test_labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few incorrect labels at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,6))\n",
    "\n",
    "for i in range(n_view): \n",
    "    sp = f.add_subplot(3, 10, i+1)\n",
    "    sp.axis('Off')\n",
    "    sp.set_title(\"{} | {}\".format(preds_incorrect[i],test_labels[idx_incorrect][i]))\n",
    "    img = imgs_incorrect[i].astype('float32')\n",
    "    plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ground truth labels\n",
    "test_labels[idx_incorrect]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot unnormalized and normalized confusion matrices. Code adapted from \n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class_names = [i for i in range(10)]\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,5))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(20,5))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
